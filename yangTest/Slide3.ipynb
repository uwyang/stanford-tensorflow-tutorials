{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple linear regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xlrd\n",
    "\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model: W*x -b, error: (f(x) - y)^2\n",
    "DATA_FILE = '../data/fire_theft.xls'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Phase 1: Assemble the graph\n",
    "# Step 1: read in data from the .xls file\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override='utf-8')\n",
    "sheet = book.sheet_by_index(0)\n",
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\n",
    "n_samples = sheet.nrows - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder for variables and labels\n",
    "x = tf.placeholder(tf.float32, name=\"x\")\n",
    "y = tf.placeholder(tf.float32, name = \"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for weight and bias\n",
    "W = tf.Variable(0.0, name = \"W\")\n",
    "b = tf.Variable(0.0, name = \"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def huber_loss(labels, predictions, delta=1.0):\n",
    "    residual = tf.abs(predictions - labels)\n",
    "    condition = tf.less(residual, delta)\n",
    "    small_res = 0.5 * tf.square(residual)\n",
    "    large_res = delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.where(condition, small_res, large_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    print(sess.run(tf.where(True, 2, 3)))N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model for prediction and loss. \n",
    "y_prediction = W*x + b\n",
    "#loss = tf.square(y - y_prediction, name = \"loss\")\n",
    "loss = huber_loss(y, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'W:0' shape=() dtype=float32_ref>\", \"<tf.Variable 'b:0' shape=() dtype=float32_ref>\"] and loss Tensor(\"Select_3:0\", dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0f642c45f01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# optimizer and gradient descent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    320\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'W:0' shape=() dtype=float32_ref>\", \"<tf.Variable 'b:0' shape=() dtype=float32_ref>\"] and loss Tensor(\"Select_3:0\", dtype=float32)."
     ]
    }
   ],
   "source": [
    "# optimizer and gradient descent. \n",
    "# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 14.002018927219545\n",
      "Epoch 1: 14.002018927219545\n",
      "Epoch 2: 14.002018927219545\n",
      "Epoch 3: 14.002018927219545\n",
      "Epoch 4: 14.002018927219545\n",
      "Epoch 5: 14.002018927219545\n",
      "Epoch 6: 14.002018927219545\n",
      "Epoch 7: 14.002018927219545\n",
      "Epoch 8: 14.002018927219545\n",
      "Epoch 9: 14.002018927219545\n",
      "Epoch 10: 14.002018927219545\n",
      "Epoch 11: 14.002018927219545\n",
      "Epoch 12: 14.002018927219545\n",
      "Epoch 13: 14.002018927219545\n",
      "Epoch 14: 14.002018927219545\n",
      "Epoch 15: 14.002018927219545\n",
      "Epoch 16: 14.002018927219545\n",
      "Epoch 17: 14.002018927219545\n",
      "Epoch 18: 14.002018927219545\n",
      "Epoch 19: 14.002018927219545\n",
      "Epoch 20: 14.002018927219545\n",
      "Epoch 21: 14.002018927219545\n",
      "Epoch 22: 14.002018927219545\n",
      "Epoch 23: 14.002018927219545\n",
      "Epoch 24: 14.002018927219545\n",
      "Epoch 25: 14.002018927219545\n",
      "Epoch 26: 14.002018927219545\n",
      "Epoch 27: 14.002018927219545\n",
      "Epoch 28: 14.002018927219545\n",
      "Epoch 29: 14.002018927219545\n",
      "Epoch 30: 14.002018927219545\n",
      "Epoch 31: 14.002018927219545\n",
      "Epoch 32: 14.002018927219545\n",
      "Epoch 33: 14.002018927219545\n",
      "Epoch 34: 14.002018927219545\n",
      "Epoch 35: 14.002018927219545\n",
      "Epoch 36: 14.002018927219545\n",
      "Epoch 37: 14.002018927219545\n",
      "Epoch 38: 14.002018927219545\n",
      "Epoch 39: 14.002018927219545\n",
      "Epoch 40: 14.002018927219545\n",
      "Epoch 41: 14.002018927219545\n",
      "Epoch 42: 14.002018927219545\n",
      "Epoch 43: 14.002018927219545\n",
      "Epoch 44: 14.002018927219545\n",
      "Epoch 45: 14.002018927219545\n",
      "Epoch 46: 14.002018927219545\n",
      "Epoch 47: 14.002018927219545\n",
      "Epoch 48: 14.002018927219545\n",
      "Epoch 49: 14.002018927219545\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument 1.9974703 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 267\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    268\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2502\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[0;32m-> 2503\u001b[0;31m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   2504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a float32 into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-35c7dcc23cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Step 9: output the values of w and b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \"\"\"\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \"\"\"\n\u001b[1;32m    336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \"\"\"\n\u001b[1;32m    336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/.conda/envs/tensorflow35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    269\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    270\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    272\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument 1.9974703 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\t# Step 7: initialize the necessary variables, in this case, w and b\n",
    "\tsess.run(tf.global_variables_initializer()) \n",
    "\t\n",
    "\twriter = tf.summary.FileWriter('./graphs/linear_reg', sess.graph)\n",
    "\t\n",
    "\t# Step 8: train the model\n",
    "\tfor i in range(50): # train the model 100 epochs, going through data 50 times. \n",
    "\t\ttotal_loss = 0\n",
    "\t\tfor datax, datay in data:\n",
    "\t\t\t# Session runs train_op and fetch values of loss\n",
    "\t\t\t_, l = sess.run([optimizer, loss], feed_dict={x: datax, y:datay}) \n",
    "\t\t\ttotal_loss += l\n",
    "\t\tprint('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    "\n",
    "\t# close the writer when you're done using it\n",
    "\twriter.close() \n",
    "\t\n",
    "\t# Step 9: output the values of w and b\n",
    "\tW, b = sess.run([W, b]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXfoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b9f7731d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * W + b, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/03/linear_reg',\n",
    "sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9974703, 12.568723)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow35",
   "language": "python",
   "name": "tensorflow35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
